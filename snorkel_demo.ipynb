{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snorkel-demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fastforwardlabs/snorkel-demo-colab/blob/master/snorkel_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2hgkWoEUODX",
        "colab_type": "text"
      },
      "source": [
        "# Training a text classification model using noisy regular expressions\n",
        "\n",
        "In this notebook we will walk through a simple text classification problem that trains a complaint classifier using data from [Consumer Financial Protection Bureau](https://www.consumerfinance.gov/data-research/consumer-complaints/), showing how to use Snorkel for weak supervision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaf5CrXPsVOI",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n13vH4IdX2N5",
        "colab_type": "text"
      },
      "source": [
        "Installing Snorkel and other required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q40cmhf21u79",
        "colab_type": "code",
        "outputId": "3a397896-6f0f-4202-b8e0-71aa940f439a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install -r requirements.txt\n",
        "!pip3 install git+https://github.com/nishamuktewar/snorkel\n",
        "!pip3 install treedlib\n",
        "!pip3 install numbskull"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4==4.7.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (4.7.1)\n",
            "Requirement already satisfied: future==0.17.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.17.1)\n",
            "Requirement already satisfied: ipywidgets==7.4.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (7.4.2)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: lxml==4.3.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (4.3.3)\n",
            "Requirement already satisfied: matplotlib==3.0.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (3.0.1)\n",
            "Requirement already satisfied: nltk==3.2.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.2.5)\n",
            "Requirement already satisfied: numba==0.43.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.43.1)\n",
            "Requirement already satisfied: numpy==1.16.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (1.16.1)\n",
            "Requirement already satisfied: pandas==0.24.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.24.2)\n",
            "Requirement already satisfied: py4j==0.10.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (0.10.8.1)\n",
            "Requirement already satisfied: requests==2.22.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (2.22.0)\n",
            "Requirement already satisfied: runipy==0.1.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 13)) (0.1.5)\n",
            "Requirement already satisfied: scipy==1.2.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 14)) (1.2.1)\n",
            "Requirement already satisfied: six==1.12.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 15)) (1.12.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 16)) (2.1.4)\n",
            "Requirement already satisfied: sqlalchemy==1.3.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 17)) (1.3.3)\n",
            "Requirement already satisfied: tika==1.19 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 18)) (1.19)\n",
            "Requirement already satisfied: tqdm==4.32.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 19)) (4.32.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 20)) (0.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.6/dist-packages (from beautifulsoup4==4.7.1->-r requirements.txt (line 1)) (1.9.2)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.4.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.3.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.6.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 4)) (5.5.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 4)) (6.0.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 4)) (4.5.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 4)) (5.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r requirements.txt (line 6)) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r requirements.txt (line 6)) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: llvmlite>=0.28.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba==0.43.1->-r requirements.txt (line 8)) (0.29.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->-r requirements.txt (line 10)) (2018.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 12)) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 12)) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 12)) (3.0.4)\n",
            "Requirement already satisfied: Pygments>=1.6 in /usr/local/lib/python3.6/dist-packages (from runipy==0.1.5->-r requirements.txt (line 13)) (2.1.3)\n",
            "Requirement already satisfied: pyzmq>=14.1.0 in /usr/local/lib/python3.6/dist-packages (from runipy==0.1.5->-r requirements.txt (line 13)) (17.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from runipy==0.1.5->-r requirements.txt (line 13)) (2.10.1)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (2.0.1)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (7.0.4)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (0.9.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (0.2.2)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (2.6.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (0.0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (2.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (1.0.2)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (0.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tika==1.19->-r requirements.txt (line 18)) (41.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r requirements.txt (line 20)) (0.21.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.4.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.7.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (1.0.16)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.7.5)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.5.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.4.2->-r requirements.txt (line 3)) (5.2.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.3)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 4)) (0.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7.2->runipy==0.1.5->-r requirements.txt (line 13)) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 20)) (0.13.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.1.7)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.5.1)\n",
            "Collecting git+https://github.com/nishamuktewar/snorkel\n",
            "  Cloning https://github.com/nishamuktewar/snorkel to /tmp/pip-req-build-iwsmlw76\n",
            "  Running command git clone -q https://github.com/nishamuktewar/snorkel /tmp/pip-req-build-iwsmlw76\n",
            "Requirement already satisfied (use --upgrade to upgrade): snorkel==0.7.0b0 from git+https://github.com/nishamuktewar/snorkel in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: snorkel\n",
            "  Building wheel for snorkel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-69shhwe9/wheels/1c/dc/7b/9cf55b0576fad8e74e4e4c004231d1fd2814b01915d5582ba2\n",
            "Successfully built snorkel\n",
            "Requirement already satisfied: treedlib in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from treedlib) (4.3.3)\n",
            "Requirement already satisfied: numbskull in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from numbskull) (0.17.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyPnpQ6t1-D-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNCpKXv1uwfz",
        "colab_type": "text"
      },
      "source": [
        "Disabling warning messages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf-MTJzpuTpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ongFEcu9YhSC",
        "colab_type": "text"
      },
      "source": [
        "Loading necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnphVByC2D4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import sklearn\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from snorkel import SnorkelSession\n",
        "from snorkel.models import candidate_subclass, Context, Candidate, StableLabel\n",
        "from snorkel.contrib.models.text import RawText\n",
        "from snorkel.annotations import LabelAnnotator\n",
        "from snorkel.learning import GenerativeModel\n",
        "from snorkel.annotations import save_marginals\n",
        "from snorkel.learning.tensorflow import TextRNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2zUynbBUfV0",
        "colab_type": "text"
      },
      "source": [
        "## Download data, if it doesn't *exist*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1TWYOoI2Tnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"./data\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "    !curl https://data.consumerfinance.gov/api/views/s6ew-h6mp/rows.csv?accessType=DOWNLOAD > ./data/complaints.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS5CHRYDUmfW",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing\n",
        "Data load, filtering out irrelevant fields and rows. Each row in the final dataframe - complaints_df consists of a \"complaint\" field and an associated ground truth label = (1, -1). These ground truth labels are used to review the performance of the labeling process, afterall the whole idea is to do without any labeled data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7govEII2gM3",
        "colab_type": "code",
        "outputId": "234ca861-809f-444a-9f21-30fd219efc66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "complaints = pd.read_csv(os.path.join(data_dir,'complaints.csv'))\n",
        "complaints.info()\n",
        "complaints.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5,6,11,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1323912 entries, 0 to 1323911\n",
            "Data columns (total 18 columns):\n",
            "Date received                   1323912 non-null object\n",
            "Product                         1323912 non-null object\n",
            "Sub-product                     1088746 non-null object\n",
            "Issue                           1323912 non-null object\n",
            "Sub-issue                       787656 non-null object\n",
            "Consumer complaint narrative    393434 non-null object\n",
            "Company public response         471011 non-null object\n",
            "Company                         1323912 non-null object\n",
            "State                           1303114 non-null object\n",
            "ZIP code                        1202868 non-null object\n",
            "Tags                            181223 non-null object\n",
            "Consumer consent provided?      715997 non-null object\n",
            "Submitted via                   1323912 non-null object\n",
            "Date sent to company            1323912 non-null object\n",
            "Company response to consumer    1323905 non-null object\n",
            "Timely response?                1323912 non-null object\n",
            "Consumer disputed?              768501 non-null object\n",
            "Complaint ID                    1323912 non-null int64\n",
            "dtypes: int64(1), object(17)\n",
            "memory usage: 181.8+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1323912, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gwjyL9jUz48",
        "colab_type": "text"
      },
      "source": [
        "### Subset data to include products with narrative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BcTLpTu2iV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "products_w_narrative = complaints[complaints['Product'].notnull() & \n",
        "                                  complaints['Consumer complaint narrative'].notnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aswvj9bu2mJt",
        "colab_type": "code",
        "outputId": "40ae3030-d680-49e5-e2bf-93d802f5d983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "print(products_w_narrative['Product'].unique())\n",
        "print(products_w_narrative['Product'].value_counts())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Credit reporting, credit repair services, or other personal consumer reports'\n",
            " 'Debt collection' 'Credit card or prepaid card' 'Mortgage'\n",
            " 'Payday loan, title loan, or personal loan' 'Student loan'\n",
            " 'Money transfer, virtual currency, or money service'\n",
            " 'Vehicle loan or lease' 'Checking or savings account' 'Credit card'\n",
            " 'Credit reporting' 'Bank account or service' 'Consumer Loan'\n",
            " 'Payday loan' 'Prepaid card' 'Money transfers' 'Other financial service'\n",
            " 'Virtual currency']\n",
            "Credit reporting, credit repair services, or other personal consumer reports    96687\n",
            "Debt collection                                                                 88701\n",
            "Mortgage                                                                        53810\n",
            "Credit reporting                                                                31588\n",
            "Credit card or prepaid card                                                     22425\n",
            "Student loan                                                                    22253\n",
            "Credit card                                                                     18838\n",
            "Bank account or service                                                         14885\n",
            "Checking or savings account                                                     13491\n",
            "Consumer Loan                                                                    9474\n",
            "Vehicle loan or lease                                                            5981\n",
            "Money transfer, virtual currency, or money service                               5675\n",
            "Payday loan, title loan, or personal loan                                        4624\n",
            "Payday loan                                                                      1747\n",
            "Money transfers                                                                  1497\n",
            "Prepaid card                                                                     1450\n",
            "Other financial service                                                           292\n",
            "Virtual currency                                                                   16\n",
            "Name: Product, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJPUhu9ucDMC",
        "colab_type": "text"
      },
      "source": [
        "### Selects two types of products - credit reporting and mortgage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGAhdow-2oT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# credit reporting only\n",
        "credit_reporting = products_w_narrative[products_w_narrative['Product'] == \n",
        "                                        'Credit reporting, ' + \n",
        "                                        'credit repair services, or other personal consumer reports']\n",
        "# mortgage only\n",
        "mortgage = products_w_narrative[products_w_narrative['Product'] == 'Mortgage']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT9hYjQD2qvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "credit_narrative = credit_reporting['Consumer complaint narrative'].values\n",
        "positive_labels = pd.Series(np.ones(credit_narrative.shape[0]))\n",
        "positive_df = pd.DataFrame({'complaint': credit_narrative, 'label': \n",
        "                            positive_labels})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev-bLnW02skW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mortgage_narrative = mortgage['Consumer complaint narrative'].values\n",
        "negative_labels = pd.Series(np.full(mortgage_narrative.shape[0], -1))\n",
        "negative_df = pd.DataFrame({'complaint': mortgage_narrative, 'label': \n",
        "                            negative_labels})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2MfDm0XU8H5",
        "colab_type": "text"
      },
      "source": [
        "### Combine into one dataframe, create labels \n",
        "(1 for credit reporting, -1 for mortgage)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZZP4-on2ukd",
        "colab_type": "code",
        "outputId": "f6f4dba3-8b96-42bd-81c8-a662fc6e8e3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "complaints_df = pd.concat([positive_df, negative_df], ignore_index=True)\n",
        "complaints_df.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150497, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rX87qAw2wvc",
        "colab_type": "code",
        "outputId": "64ef18ab-582d-4587-8ad2-aa968c08f4f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "complaints_df['label'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1.0    96687\n",
              "-1.0    53810\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rJlMTGxVDPE",
        "colab_type": "text"
      },
      "source": [
        "### Split data into train, dev, test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkY-5o7D2zFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, testval = train_test_split(complaints_df, test_size=0.2, random_state=123)\n",
        "dev, test = train_test_split(testval, test_size=0.5, random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kv7_632VFL3",
        "colab_type": "text"
      },
      "source": [
        "## Create noisy labeling functions\n",
        "\n",
        "Our assumption is that we don't have the ground truth labels for our data, but instead have these noisy and possibly conflicting labels based on regular expressions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjA7CEoUci2C",
        "colab_type": "text"
      },
      "source": [
        "### Regular expressions that define words, phrases, actions for use in labeling functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i70mzuQ421Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AGENCY_NAMES = r'\\bexperian\\b|\\btransunion\\b|\\bequifax\\b|\\bfcra\\b'   \n",
        "DEBT_MENTIONS = r'\\bcollector\\b|\\bdebt\\b|\\bcreditor\\b'\n",
        "ADDRESS_MENTIONS = r'\\baddress\\b'\n",
        "DESCRIPTIONS = r'\\binaccura|\\bcompromise'\n",
        "IDENTITY = r'\\bidentity'\n",
        "CREDIT_REPORT_MENTIONS = r'\\bcredit (report|agency|reporting|bureau|agencies)'              \n",
        "MORTGAGE_MENTIONS = r'\\bloan\\b|\\bmortgage\\|\\bprepayment\\b|\\bprincipal\\b|\\binterest\\b|\\bescrow\\b'\n",
        "CHECKS = r'\\bcheck'\n",
        "TAXES = r'\\btax'\n",
        "LEASE = r'\\blease'\n",
        "HOUSE_MENTIONS = r'\\bhouse\\b|\\bhome\\bcondo\\b'\n",
        "MORTGAGE_HELP_ACTIONS = r'\\bmitigat|\\bmodifi\\brefinanc'\n",
        "MORTGAGE_COMPONENTS = r'\\bequity\\b|\\bdownpayment\\b|\\bshortage\\b'\n",
        "POSITIVE_ACTIONS = r'\\bremov|\\bdispute\\b' \n",
        "INQUIRY_ACTIONS  = r'\\binquir\\b|\\berror\\b'\n",
        "NEGATIVE_ACTIONS = r'\\bpredator|\\bapprove|\\bservic|\\bappraise|\\bforeclos'  \n",
        "                                                                      \n",
        "FRAUD = r'\\bfraudulent (account|charges)'                                               \n",
        "MONEYXFER = r'\\bmoney transfer'                                                         \n",
        "CREDIT_REPORTING = r'\\b(identity has been compromise(|d)|data breaches|inquiries to bus\\\n",
        "inesses|mistakes appear in my report|reporting incorrectly|dispute(|d)|(t|T)ransunion|derog\\\n",
        "atory|experian|identity theft)'                                                             \n",
        "CREDIT_REPAIR = r'\\b(credit repair|hard inquiry|inquiries to businesses|mistakes appear\\\n",
        " in my report|reporting incorrectly)'       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQzYfavwdWad",
        "colab_type": "text"
      },
      "source": [
        "### Labeling functions that help provide weak supervision\n",
        "\n",
        "In other words, instead of hand-labeling data to create a training set for our model, we write functions that look something like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0a_eu1223tT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lf_agency_names(complaint):                                                                   \n",
        "    if re.search(AGENCY_NAMES, str(complaint), re.IGNORECASE):                            \n",
        "        return 1                                                                            \n",
        "    else:                                                                                   \n",
        "        return 0            \n",
        "\n",
        "def lf_debt(complaint):                                                            \n",
        "    if re.search(DEBT_MENTIONS, str(complaint), re.IGNORECASE):                           \n",
        "        return 1                                                                            \n",
        "    else:                                                                                   \n",
        "        return 0      \n",
        "\n",
        "def lf_address(complaint):                                                            \n",
        "    if re.search(ADDRESS_MENTIONS, str(complaint), re.IGNORECASE):\n",
        "        return 1                                                                            \n",
        "    else:                                                                                   \n",
        "        return 0     \n",
        "    \n",
        "def lf_credit_report(complaint):                                                           \n",
        "    if re.search(CREDIT_REPORT_MENTIONS, str(complaint), re.IGNORECASE):                          \n",
        "        return 1                                                                            \n",
        "    else:                                                                                   \n",
        "        return 0             \n",
        "    \n",
        "def lf_credit_actions(complaint):                                                           \n",
        "    if re.search(POSITIVE_ACTIONS, str(complaint), re.IGNORECASE):                          \n",
        "        return 1                                                                            \n",
        "    else:                                                                                   \n",
        "        return 0             \n",
        "    \n",
        "def lf_mortgage(complaint):                                                                 \n",
        "    if re.search(MORTGAGE_MENTIONS, str(complaint), re.IGNORECASE):                            \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0        \n",
        "    \n",
        "def lf_inquiry(complaint):                                                                 \n",
        "    if re.search(INQUIRY_ACTIONS, str(complaint), re.IGNORECASE):                            \n",
        "        return 1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0        \n",
        "    \n",
        "def lf_house_mentions(complaint):                                                         \n",
        "    if re.search(HOUSE_MENTIONS, str(complaint), re.IGNORECASE):                          \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0          \n",
        "    \n",
        "def lf_mortgage_help(complaint):                                                         \n",
        "    if re.search(MORTGAGE_HELP_ACTIONS, str(complaint), re.IGNORECASE):                          \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0          \n",
        "    \n",
        "def lf_mortgage_components(complaint):                                                         \n",
        "    if re.search(MORTGAGE_COMPONENTS, str(complaint), re.IGNORECASE):                          \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0          \n",
        "    \n",
        "def lf_fraud(complaint):                                                                    \n",
        "    if (re.search(FRAUD, str(complaint), re.IGNORECASE)                                     \n",
        "        and not re.search(MONEYXFER, str(complaint), re.IGNORECASE)):                       \n",
        "        return 1                                                                            \n",
        "    elif (re.search(FRAUD, str(complaint), re.IGNORECASE)                                   \n",
        "          and re.search(MONEYXFER, str(complaint), re.IGNORECASE)):                         \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0     \n",
        "    \n",
        "def lf_reporting(complaint):                                                                \n",
        "    if (re.search(CREDIT_REPORTING, str(complaint), re.IGNORECASE)                          \n",
        "        and not re.search(MONEYXFER, str(complaint), re.IGNORECASE)):                       \n",
        "        return 1                                                                            \n",
        "    elif (re.search(CREDIT_REPORTING, str(complaint), re.IGNORECASE)                        \n",
        "           and re.search(MONEYXFER, str(complaint), re.IGNORECASE)):                        \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0     \n",
        "\n",
        "def lf_repair(complaint):                                                                   \n",
        "    if (re.search(CREDIT_REPAIR, str(complaint), re.IGNORECASE)                             \n",
        "        and not re.search(MONEYXFER, str(complaint), re.IGNORECASE)                         \n",
        "        and not re.search(CREDIT_REPORTING, str(complaint), re.IGNORECASE)                  \n",
        "       ):                                                                                   \n",
        "        return 1                                                                            \n",
        "    elif ((re.search(CREDIT_REPAIR, str(complaint), re.IGNORECASE)                          \n",
        "           and re.search(MONEYXFER, str(complaint), re.IGNORECASE))                         \n",
        "          or                                                                                \n",
        "          (re.search(CREDIT_REPAIR, str(complaint), re.IGNORECASE)                          \n",
        "           and re.search(CREDIT_REPORTING, str(complaint), re.IGNORECASE))                  \n",
        "         ):                                                                                 \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0  \n",
        "\n",
        "def lf_credit_description(complaint):                                                                \n",
        "    if (re.search(DESCRIPTIONS, str(complaint), re.IGNORECASE)                          \n",
        "        and re.search(IDENTITY, str(complaint), re.IGNORECASE)):                       \n",
        "        return 1                                                                                                                                             \n",
        "    else:                                                                                   \n",
        "        return 0           \n",
        "    \n",
        "def lf_description_not_mortgage(complaint):                                                                \n",
        "    if (re.search(DESCRIPTIONS, str(complaint), re.IGNORECASE)                          \n",
        "        and not re.search(MORTGAGE_MENTIONS, str(complaint), re.IGNORECASE)):                       \n",
        "        return 1                                                                                                                                             \n",
        "    else:                                                                                   \n",
        "        return 0           \n",
        "    \n",
        "def lf_tax(complaint):                                                         \n",
        "    if re.search(TAXES, str(complaint), re.IGNORECASE):                          \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0    \n",
        "    \n",
        "def lf_check(complaint):                                                         \n",
        "    if re.search(CHECKS, str(complaint), re.IGNORECASE):                          \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0    \n",
        "    \n",
        "def lf_lease(complaint):                                                         \n",
        "    if re.search(LEASE, str(complaint), re.IGNORECASE):                          \n",
        "        return 1                                                                          \n",
        "    else:                                                                                   \n",
        "        return 0    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_pBGXxdVTKV",
        "colab_type": "text"
      },
      "source": [
        "## Generate Snorkel objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1GW0OCXVUJi",
        "colab_type": "text"
      },
      "source": [
        "### Candidates and Contexts\n",
        "\n",
        "Candidate objects in Snorkel represent objects to be classified. In this case we are interested in classifying whether a complaint narrative is positive -that is credit related or not. All Candidate objects point to one or more Context objects representing the raw data that they are rooted in. In this case, our candidates will each point to a single Context object representing the raw text of the complaint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjVSxCjz26NK",
        "colab_type": "code",
        "outputId": "7f841b82-9224-4d8f-ee37-0931ff4eaee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "session = SnorkelSession()\n",
        "\n",
        "values = list(complaints_df.label.unique())\n",
        "print(values)\n",
        "\n",
        "# snorkel candidate, value if none defaults to binary (true, false)\n",
        "Narrative = candidate_subclass('Narrative', ['narrative'], values=values)\n",
        "\n",
        "# Make sure DB is cleared\n",
        "session.query(Context).delete()\n",
        "session.query(Candidate).delete()\n",
        "session.query(StableLabel).delete()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, -1.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcRDtTkoViEb",
        "colab_type": "text"
      },
      "source": [
        "Once we have defined the context for each candidate, we split it into three sets :\n",
        "\n",
        "- Training set (split=0): The narratives for which we have noisy, conflicting labels from our labeling functions; we will resolve these conflicts using the generative model and then use them as training data for the discriminative model (RNN in this case). The discriminative model is the standard goal in machine learning that learns to generalize beyond the training set. It takes as input the probabilistic labels output by the generative model. \n",
        "\n",
        "- Development/ validation set (split=1): We will pretend that we do not have any noisy, conflicting labels for this split of the data, and it is used to help iterate the generative model training process. In later steps we also use it to test the discriminative model's (RNN in this case) performance on unseen data. \n",
        "\n",
        "- Test set (split=2): We will pretend that we do not have any noisy, conflicting labels for this split of the data, and use it to test the discriminative model's (RNN in this case) performance on unseen data   \n",
        "\n",
        "We then commit it to the database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jypxk-b_3BAJ",
        "colab_type": "code",
        "outputId": "494321db-09ac-4ca5-8064-38dece125ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_index = train.index\n",
        "train.index.str = np.asarray(str(x) for x in train.index)\n",
        "train_complaints = train.values[:, 0]\n",
        "train_labels = train.values[:, 1]\n",
        "\n",
        "for element in zip(train_index, train_complaints, train_labels):\n",
        "    split = 0\n",
        "    raw_text = RawText(stable_id=element[0], name=element[0], \n",
        "                       text=str(element[1]))\n",
        "    narrative = Narrative(narrative=raw_text, split=split)\n",
        "    session.add(narrative)\n",
        "\n",
        "dev_index = dev.index\n",
        "dev.index.str = np.asarray(str(x) for x in dev.index)\n",
        "dev_complaints = dev.values[:, 0]\n",
        "dev_labels = dev.values[:, 1]\n",
        "\n",
        "for element in zip(dev_index, dev_complaints, dev_labels):\n",
        "    split = 1\n",
        "    raw_text = RawText(stable_id=element[0], name=element[0], \n",
        "                       text=str(element[1]))\n",
        "    narrative = Narrative(narrative=raw_text, split=split)\n",
        "    session.add(narrative)\n",
        "\n",
        "test_index = test.index\n",
        "test.index.str = np.asarray(str(x) for x in test.index)\n",
        "test_complaints = test.values[:, 0]\n",
        "test_labels = test.values[:, 1]\n",
        "\n",
        "for element in zip(test_index, test_complaints, test_labels):\n",
        "    split = 2\n",
        "    raw_text = RawText(stable_id=element[0], name=element[0], \n",
        "                       text=str(element[1]))\n",
        "    narrative = Narrative(narrative=raw_text, split=split)\n",
        "    session.add(narrative)\n",
        "\n",
        "session.commit()\n",
        "\n",
        "# number of datapoints\n",
        "print(\"number of datapoints in candidate: \", session.query(Narrative).count())\n",
        "\n",
        "# load ground truth labels\n",
        "train_cand_labels = train_labels\n",
        "dev_cand_labels = dev_labels\n",
        "test_cand_labels = test_labels"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of datapoints in candidate:  150497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8--icqpq3JuM",
        "colab_type": "code",
        "outputId": "f906f1cd-c4e3-4abf-dda4-9648d29df701",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# test one labeling function\n",
        "labeled = []\n",
        "for c in session.query(Narrative).filter(Narrative.split == 1).all():\n",
        "    if lf_tax(c) != 0:\n",
        "        labeled.append(c)\n",
        "print(\"Number labeled:\", len(labeled))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number labeled: 1008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpOVOJiKVoSn",
        "colab_type": "text"
      },
      "source": [
        "### Labels\n",
        "\n",
        "Next, we assign labeling functions for each of the training candidates in a sparse matrix (which will also automatically be saved to the Snorkel database), with one row for each candidate and one column for each label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQnhzeaf3nrt",
        "colab_type": "code",
        "outputId": "891b33bf-1994-4813-ca58-35b823f7014d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "LFs = [lf_agency_names, lf_debt, lf_address, lf_credit_report, lf_credit_actions, \n",
        "       lf_inquiry, lf_mortgage, lf_house_mentions, lf_mortgage_components,\n",
        "       lf_mortgage_help, lf_fraud, lf_reporting, lf_repair,\n",
        "       lf_credit_description, lf_description_not_mortgage,\n",
        "       lf_tax, lf_check, lf_lease]\n",
        "# apply labeling functions\n",
        "labeler = LabelAnnotator(lfs = LFs)\n",
        "L_train = labeler.apply(split=0)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 25/120397 [00:00<08:06, 247.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Clearing existing...\n",
            "Running UDF...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 120397/120397 [07:43<00:00, 260.02it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCtH_AV-3scM",
        "colab_type": "code",
        "outputId": "6427aff0-86ac-4468-d982-b72428247fc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "# see what's going on\n",
        "print(L_train.get_candidate(session, 0))\n",
        "print(L_train.get_key(session, 0))\n",
        "print(L_train.lf_stats(session))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Narrative(Raw Text I had homesite home owners ins. It was {$2000.00} a year. I had my mortgage company pay my taxes and insurance through an escrow account. I paid {$1500.00} as a fixed price. My taxes have NOT gone up. My PMI has NOT gone up. I changed my insurance company to liberty mutual. My new yearly price is {$1000.00}. When I notified Bogman Inc. of the change, my new monthly payment only went Down {$10.00}. I have called the company 4 times. First speaking to \" XXXX '' whom did not help me, then to her manager \" XXXX XXXX ''. Who is telling me they have only been paying {$1000.00} a year for my previous years insurance, which is a lie.)\n",
            "LabelKey (lf_agency_names)\n",
            "                              j  Coverage  Overlaps  Conflicts\n",
            "lf_agency_names               0  0.280107  0.261875   0.061447\n",
            "lf_debt                       1  0.145510  0.138251   0.057659\n",
            "lf_address                    2  0.098840  0.093565   0.046571\n",
            "lf_credit_report              3  0.439920  0.397809   0.141523\n",
            "lf_credit_actions             4  0.328796  0.313405   0.109239\n",
            "lf_inquiry                    5  0.061663  0.058872   0.035906\n",
            "lf_mortgage                   6  0.353398  0.260945   0.179166\n",
            "lf_house_mentions             7  0.081240  0.073067   0.037318\n",
            "lf_mortgage_components        8  0.031687  0.030458   0.015108\n",
            "lf_mortgage_help              9  0.013655  0.011944   0.006030\n",
            "lf_fraud                     10  0.020590  0.019851   0.003987\n",
            "lf_reporting                 11  0.325224  0.318247   0.100152\n",
            "lf_repair                    12  0.027476  0.025773   0.019444\n",
            "lf_credit_description        13  0.012982  0.012982   0.002924\n",
            "lf_description_not_mortgage  14  0.078150  0.074454   0.009710\n",
            "lf_tax                       15  0.065151  0.062078   0.032983\n",
            "lf_check                     16  0.123865  0.112627   0.080093\n",
            "lf_lease                     17  0.010515  0.009851   0.005889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6CcudVdVvxk",
        "colab_type": "text"
      },
      "source": [
        "## Training generative model\n",
        "\n",
        "\n",
        "The problem with the above labeling functions is that they're noisy, conflicting and may even overlap on certain examples. The key technical idea of Snorkel's generative modeling approach is that we can automatically model and denoise them!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbo3wzLj5ukd",
        "colab_type": "code",
        "outputId": "88190695-ef27-4578-92a2-f2076ea1a070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Initialize Snorkel's generative model for\n",
        "# learning the different worker accuracies.\n",
        "gen_model = GenerativeModel(lf_propensity=True)\n",
        "gen_model.train(L_train, epochs=20, decay=0.95, step_size=0.1/L_train.shape[0], \n",
        "                reg_param=1e-6)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inferred cardinality: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XgNEwhsV31e",
        "colab_type": "text"
      },
      "source": [
        "## Applying the generative model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiKU0A_2gjZU",
        "colab_type": "text"
      },
      "source": [
        "### Probabilistic Label Statistics\n",
        "\n",
        "We view the distribution of weak labels produced by our generative model. Note that the samples in the 0.5 bucket indicate the ones that have no LF coverage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7-pU4eS5_Na",
        "colab_type": "code",
        "outputId": "b09ecbd7-3e83-4dd7-cb2a-af57350081fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "train_marginals = gen_model.marginals(L_train)\n",
        "plt.hist(train_marginals, bins=20)\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAFPRJREFUeJzt3X+sX/V93/HnKwYStiTFhFuEbG9m\njavOYaohd+Cq05bCYgyRYqqlEUgtLkJxl8DUblEVp5NGCkECTUkkJELnCBdTtTGMtsNqTD2LMKFM\nM3ApBDA04xZIsUfgFvOjESoZ5L0/vh+v3/jc6/v1/fW99n0+pKN7zvt8zvl+PtdX93XPOZ/v16kq\nJEnq955hd0CStPgYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1nDTsDszUGWec\nUatXrx52NyTpuPLoo4/+TVWNTNfuuA2H1atXMzY2NuxuSNJxJcn3B2nnbSVJUofhIEnqMBwkSR2G\ngySpw3CQJHUYDpKkjmnDIcn7kjyc5LtJ9if53Va/I8nzSR5vy7pWT5JbkowneSLJeX3n2pzk2bZs\n7qt/NMmT7ZhbkmQ+BitJGswg73N4G7iwqn6Y5GTgO0nua/t+u6ruOaL9JcCatlwA3AZckOR04Dpg\nFCjg0SS7quq11uYzwEPAbmAjcB+SpKGY9sqhen7YNk9uy9H+4+lNwJ3tuH3AaUnOAi4G9lbVoRYI\ne4GNbd8Hq2pf9f5D6zuBy2YxJknSLA30Dukky4BHgQ8Dt1bVQ0k+C9yY5D8B9wNbq+ptYAXwYt/h\nB1rtaPUDk9Ql6YS0euu3ZnzsCzd9Yg57MrWBHkhX1btVtQ5YCZyf5Bzgi8DPAf8cOB34wrz1skmy\nJclYkrGJiYn5fjlJWrKOabZSVb0OPABsrKqX2q2jt4HfB85vzQ4Cq/oOW9lqR6uvnKQ+2etvq6rR\nqhodGZn2c6MkSTM0yGylkSSntfVTgY8Df9meFdBmFl0GPNUO2QVc2WYtrQfeqKqXgD3AhiTLkywH\nNgB72r43k6xv57oSuHduhylJOhaDPHM4C9jRnju8B7i7qv4sybeTjAABHgf+bWu/G7gUGAfeAq4C\nqKpDSW4AHmntrq+qQ239c8AdwKn0Zik5U0mShmjacKiqJ4BzJ6lfOEX7Aq6ZYt92YPsk9THgnOn6\nIklaGL5DWpLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofh\nIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkd04ZDkvcleTjJd5Ps\nT/K7rX52koeSjCe5K8kprf7etj3e9q/uO9cXW/17SS7uq29stfEkW+d+mJKkYzHIlcPbwIVV9fPA\nOmBjkvXAzcDXqurDwGvA1a391cBrrf611o4ka4HLgY8AG4GvJ1mWZBlwK3AJsBa4orWVJA3JtOFQ\nPT9smye3pYALgXtafQdwWVvf1LZp+y9KklbfWVVvV9XzwDhwflvGq+q5qvoRsLO1lSQNyUDPHNpf\n+I8DrwB7gb8CXq+qd1qTA8CKtr4CeBGg7X8D+FB//YhjpqpP1o8tScaSjE1MTAzSdUnSDAwUDlX1\nblWtA1bS+0v/5+a1V1P3Y1tVjVbV6MjIyDC6IElLwjHNVqqq14EHgF8ATktyUtu1EjjY1g8CqwDa\n/p8CXu2vH3HMVHVJ0pAMMltpJMlpbf1U4OPAM/RC4lOt2Wbg3ra+q23T9n+7qqrVL2+zmc4G1gAP\nA48Aa9rsp1PoPbTeNReDkyTNzEnTN+EsYEebVfQe4O6q+rMkTwM7k3wZeAy4vbW/HfiDJOPAIXq/\n7Kmq/UnuBp4G3gGuqap3AZJcC+wBlgHbq2r/nI1QknTMpg2HqnoCOHeS+nP0nj8cWf874FemONeN\nwI2T1HcDuwforyRpAfgOaUlSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofh\nIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqWPacEiyKskD\nSZ5Osj/Jb7b6l5IcTPJ4Wy7tO+aLScaTfC/JxX31ja02nmRrX/3sJA+1+l1JTpnrgUqSBjfIlcM7\nwOerai2wHrgmydq272tVta4tuwHavsuBjwAbga8nWZZkGXArcAmwFrii7zw3t3N9GHgNuHqOxidJ\nmoFpw6GqXqqqv2jrfws8A6w4yiGbgJ1V9XZVPQ+MA+e3ZbyqnquqHwE7gU1JAlwI3NOO3wFcNtMB\nSZJm75ieOSRZDZwLPNRK1yZ5Isn2JMtbbQXwYt9hB1ptqvqHgNer6p0j6pKkIRk4HJK8H/hj4Leq\n6k3gNuBngHXAS8BX5qWHP9mHLUnGkoxNTEzM98tJ0pI1UDgkOZleMPxhVf0JQFW9XFXvVtWPgW/Q\nu20EcBBY1Xf4ylabqv4qcFqSk46od1TVtqoararRkZGRQbouSZqBQWYrBbgdeKaqvtpXP6uv2S8D\nT7X1XcDlSd6b5GxgDfAw8Aiwps1MOoXeQ+tdVVXAA8Cn2vGbgXtnNyxJ0mycNH0TfhH4NeDJJI+3\n2u/Qm220DijgBeA3AKpqf5K7gafpzXS6pqreBUhyLbAHWAZsr6r97XxfAHYm+TLwGL0wkiQNybTh\nUFXfATLJrt1HOeZG4MZJ6rsnO66qnuPvb0tJkobMd0hLkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAk\ndRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH\n4SBJ6jAcJEkd04ZDklVJHkjydJL9SX6z1U9PsjfJs+3r8lZPkluSjCd5Isl5fefa3No/m2RzX/2j\nSZ5sx9ySJPMxWEnSYAa5cngH+HxVrQXWA9ckWQtsBe6vqjXA/W0b4BJgTVu2ALdBL0yA64ALgPOB\n6w4HSmvzmb7jNs5+aJKkmZo2HKrqpar6i7b+t8AzwApgE7CjNdsBXNbWNwF3Vs8+4LQkZwEXA3ur\n6lBVvQbsBTa2fR+sqn1VVcCdfeeSJA3BMT1zSLIaOBd4CDizql5qu34AnNnWVwAv9h12oNWOVj8w\nSV2SNCQDh0OS9wN/DPxWVb3Zv6/9xV9z3LfJ+rAlyViSsYmJifl+OUlasgYKhyQn0wuGP6yqP2nl\nl9stIdrXV1r9ILCq7/CVrXa0+spJ6h1Vta2qRqtqdGRkZJCuS5JmYJDZSgFuB56pqq/27doFHJ5x\ntBm4t69+ZZu1tB54o91+2gNsSLK8PYjeAOxp+95Msr691pV955IkDcFJA7T5ReDXgCeTPN5qvwPc\nBNyd5Grg+8Cn277dwKXAOPAWcBVAVR1KcgPwSGt3fVUdauufA+4ATgXua4skaUimDYeq+g4w1fsO\nLpqkfQHXTHGu7cD2SepjwDnT9UWStDB8h7QkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeow\nHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNB\nktRhOEiSOqYNhyTbk7yS5Km+2peSHEzyeFsu7dv3xSTjSb6X5OK++sZWG0+yta9+dpKHWv2uJKfM\n5QAlScdukCuHO4CNk9S/VlXr2rIbIMla4HLgI+2YrydZlmQZcCtwCbAWuKK1Bbi5nevDwGvA1bMZ\nkCRp9qYNh6p6EDg04Pk2ATur6u2qeh4YB85vy3hVPVdVPwJ2ApuSBLgQuKcdvwO47BjHIEmaY7N5\n5nBtkifabaflrbYCeLGvzYFWm6r+IeD1qnrniLokaYhmGg63AT8DrANeAr4yZz06iiRbkowlGZuY\nmFiIl5SkJWlG4VBVL1fVu1X1Y+Ab9G4bARwEVvU1XdlqU9VfBU5LctIR9aled1tVjVbV6MjIyEy6\nLkkawIzCIclZfZu/DByeybQLuDzJe5OcDawBHgYeAda0mUmn0HtovauqCngA+FQ7fjNw70z6JEma\nOydN1yDJN4GPAWckOQBcB3wsyTqggBeA3wCoqv1J7gaeBt4Brqmqd9t5rgX2AMuA7VW1v73EF4Cd\nSb4MPAbcPmejkyTNyLThUFVXTFKe8hd4Vd0I3DhJfTewe5L6c/z9bSlJ0iLgO6QlSR2GgySpw3CQ\nJHUYDpKkDsNBktRhOEiSOqadyirNxuqt35rxsS/c9Ik57ImkY+GVgySpw3CQJHUYDpKkDsNBktRh\nOEiSOgwHSVKHU1klaQZmM037eGA4SJPw/Rla6rytJEnqMBwkSR2GgySpw3CQJHUYDpKkjmnDIcn2\nJK8keaqvdnqSvUmebV+Xt3qS3JJkPMkTSc7rO2Zza/9sks199Y8mebIdc0uSzPUgJUnHZpArhzuA\njUfUtgL3V9Ua4P62DXAJsKYtW4DboBcmwHXABcD5wHWHA6W1+UzfcUe+liRpgU0bDlX1IHDoiPIm\nYEdb3wFc1le/s3r2AaclOQu4GNhbVYeq6jVgL7Cx7ftgVe2rqgLu7DuXJGlIZvrM4cyqeqmt/wA4\ns62vAF7sa3eg1Y5WPzBJXZI0RLN+IN3+4q856Mu0kmxJMpZkbGJiYiFeUpKWpJmGw8vtlhDt6yut\nfhBY1dduZasdrb5ykvqkqmpbVY1W1ejIyMgMuy5Jms5Mw2EXcHjG0Wbg3r76lW3W0nrgjXb7aQ+w\nIcny9iB6A7Cn7Xszyfo2S+nKvnNJkoZk2g/eS/JN4GPAGUkO0Jt1dBNwd5Krge8Dn27NdwOXAuPA\nW8BVAFV1KMkNwCOt3fVVdfgh9+fozYg6FbivLZKkIZo2HKrqiil2XTRJ2wKumeI824Htk9THgHOm\n64ckaeH4DmlJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktQx7fscdGJYvfVbMz72hZs+MYc9\nkXQ88MpBktRhOEiSOrytJOm4NZvbpeAt06PxykGS1OGVg6Qla7ZXHicyrxwkSR2GgySpw3CQJHUY\nDpKkDsNBktRhOEiSOpzKKmmonE66OHnlIEnqmFU4JHkhyZNJHk8y1mqnJ9mb5Nn2dXmrJ8ktScaT\nPJHkvL7zbG7tn02yeXZDkiTN1lxcOfxSVa2rqtG2vRW4v6rWAPe3bYBLgDVt2QLcBr0wAa4DLgDO\nB647HCiSpOGYj9tKm4AdbX0HcFlf/c7q2QecluQs4GJgb1UdqqrXgL3AxnnolyRpQLMNhwL+e5JH\nk2xptTOr6qW2/gPgzLa+Anix79gDrTZVvSPJliRjScYmJiZm2XVJ0lRmO1vpX1TVwSQ/DexN8pf9\nO6uqktQsX6P/fNuAbQCjo6Nzdl5J0k+a1ZVDVR1sX18B/pTeM4OX2+0i2tdXWvODwKq+w1e22lR1\nSdKQzDgckvzDJB84vA5sAJ4CdgGHZxxtBu5t67uAK9uspfXAG+320x5gQ5Ll7UH0hlaTJA3JbG4r\nnQn8aZLD5/mjqvrzJI8Adye5Gvg+8OnWfjdwKTAOvAVcBVBVh5LcADzS2l1fVYdm0S9J0izNOByq\n6jng5yepvwpcNEm9gGumONd2YPtM+yJJmlu+Q1qS1GE4SJI6DAdJUofhIEnq8CO7Jc2aH7t94jEc\ntGjN9hfOCzd9Yo56Ii093laSJHV45SDNsdlc8cz2asfbO5orXjlIkjoMB0lSh7eVFpAPWCUdL7xy\nkCR1GA6SpA7DQZLUYThIkjoMB0lSh7OVpEXEN7FpsfDKQZLUYThIkjoMB0lSx6IJhyQbk3wvyXiS\nrcPujyQtZYvigXSSZcCtwMeBA8AjSXZV1dPD7VnXUnxgeLyO+Xjtt7QYLJYrh/OB8ap6rqp+BOwE\nNg25T5K0ZC2KKwdgBfBi3/YB4IIh9WXR8i9hSQtlsYTDQJJsAba0zR8meRX4myF2adjOYOmOfymP\nHRz/kh1/bp712P/xII0WSzgcBFb1ba9stZ9QVduAbYe3k4xV1ej8d29xWsrjX8pjB8e/lMe/UGNf\nLM8cHgHWJDk7ySnA5cCuIfdJkpasRXHlUFXvJLkW2AMsA7ZX1f4hd0uSlqxFEQ4AVbUb2H2Mh22b\nvskJbSmPfymPHRz/Uh7/gow9VbUQryNJOo4slmcOkqRF5LgIh+k+WiPJe5Pc1fY/lGT1wvdyfgww\n9v+Q5OkkTyS5P8lA09SOF4N+rEqSf5OkkpxQM1gGGX+ST7efgf1J/mih+zhfBvjZ/0dJHkjyWPv5\nv3QY/ZwvSbYneSXJU1PsT5Jb2vfniSTnzWkHqmpRL/QeUP8V8E+AU4DvAmuPaPM54Pfa+uXAXcPu\n9wKO/ZeAf9DWP3uijH3Q8bd2HwAeBPYBo8Pu9wL/+68BHgOWt+2fHna/F3Ds24DPtvW1wAvD7vcc\nfw/+JXAe8NQU+y8F7gMCrAcemsvXPx6uHAb5aI1NwI62fg9wUZIsYB/ny7Rjr6oHquqttrmP3ntE\nThSDfqzKDcDNwN8tZOcWwCDj/wxwa1W9BlBVryxwH+fLIGMv4INt/aeA/7OA/Zt3VfUgcOgoTTYB\nd1bPPuC0JGfN1esfD+Ew2UdrrJiqTVW9A7wBfGhBeje/Bhl7v6vp/SVxoph2/O1SelVVnYifLTLI\nv//PAj+b5H8m2Zdk44L1bn4NMvYvAb+a5AC9mY7/bmG6tmgc6++HY7JoprJqdpL8KjAK/Kth92Wh\nJHkP8FXg14fclWE6id6tpY/Ru2p8MMk/q6rXh9qrhXEFcEdVfSXJLwB/kOScqvrxsDt2IjgerhwG\n+WiN/98myUn0LjFfXZDeza+BPlYkyb8G/iPwyap6e4H6thCmG/8HgHOA/5HkBXr3XXedQA+lB/n3\nPwDsqqr/W1XPA/+bXlgc7wYZ+9XA3QBV9b+A99H7zKWlYqDfDzN1PITDIB+tsQvY3NY/BXy72hOb\n49y0Y09yLvBf6AXDiXK/+bCjjr+q3qiqM6pqdVWtpvfM5ZNVNTac7s65QX72/xu9qwaSnEHvNtNz\nC9nJeTLI2P8auAggyT+lFw4TC9rL4doFXNlmLa0H3qiql+bq5Iv+tlJN8dEaSa4HxqpqF3A7vUvK\ncXoPcC4fXo/nzoBj/8/A+4H/2p7B/3VVfXJonZ5DA47/hDXg+PcAG5I8DbwL/HZVHfdXzQOO/fPA\nN5L8e3oPp3/9BPmjEIAk36QX/Ge05yrXAScDVNXv0XvOcikwDrwFXDWnr38CfS8lSXPkeLitJEla\nYIaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnq+H8IJZ2OrE7WQwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tteWMMziXPx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cdda768-875a-4d26-96ec-9ea9b2095394"
      },
      "source": [
        "print(\"So we have \", (train_marginals == 0.5).sum(), \n",
        "      \" samples where the LFs do not provide any coverage!\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "So we have  10691  samples where the LFs do not provide any coverage!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdSWOLOHV8xM",
        "colab_type": "text"
      },
      "source": [
        "### Compare learned accuracies vs empirical accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BJFOfWVjNjf",
        "colab_type": "text"
      },
      "source": [
        "#### Learned accuracies from our generative model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu6pQmGf8a60",
        "colab_type": "code",
        "outputId": "a55da7f6-7e41-434e-8356-c33fb1ed628a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy = gen_model.score(L_train, train_cand_labels)\n",
        "print(\"precision: {:.5f}\".format(accuracy[0]), \n",
        "      \"recall: {:.5f}\".format(accuracy[1]), \n",
        "      \"F1: {:.5f}\".format(accuracy[2]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision: 0.85814 recall: 0.90175 F1: 0.87941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbPGL0eikcX1",
        "colab_type": "text"
      },
      "source": [
        "#### Empirical accuracies of our labeling functions - majority vote\n",
        "\n",
        "We observe that the majority vote approach does almost as well as the generative model for our use case! The labeling functions that we have defined are pretty simple, they essentially look at certain keywords. In a realistic scenario, the labeling sources may not just look at presence of some keywords but also knowledge bases, distant supervision, or even crowd-source them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAHOrwAi8wia",
        "colab_type": "code",
        "outputId": "33691835-ac78-42ed-e632-d5dcdd64519f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Collect the majority vote answer for each complaint\n",
        "mv = []\n",
        "for i in range(L_train.shape[0]):\n",
        "    #indicates that there is no coverage for a particular datapoint\n",
        "    if np.diff(L_train[i].indptr) != 0:   \n",
        "        c = Counter([L_train[i,j] for j in L_train[i].nonzero()[1]])\n",
        "        mv.append(c.most_common(1)[0][0])\n",
        "    else:\n",
        "        # assume that no label is equivalent to abstaining\n",
        "        mv.append(0) \n",
        "mv = np.array(mv)\n",
        "\n",
        "# Count the number correct by majority vote\n",
        "n_correct = np.sum([1 for i in range(L_train.shape[0]) if mv[i] == \n",
        "                    train_cand_labels[i]])\n",
        "print (\"Accuracy:{}\".format(n_correct / float(L_train.shape[0])))\n",
        "print (\"Number incorrect:{}\".format(L_train.shape[0] - n_correct))\n",
        "\n",
        "# Compute and return precision, recall\n",
        "tp = (0.5 * (mv * train_cand_labels + 1))[mv == 1].sum()\n",
        "pred_pos = mv[mv == 1].sum()\n",
        "p = tp / float(pred_pos) if pred_pos > 0 else 0.0\n",
        "pos = train_cand_labels[train_cand_labels == 1].sum()\n",
        "r = tp / float(pos) if pos > 0 else 0.0\n",
        "\n",
        "# Compute general F-beta score\n",
        "beta=1\n",
        "if p + r > 0:\n",
        "    f_beta = (1 + beta**2) * ((p * r) / (((beta**2) * p) + r))\n",
        "else:\n",
        "    f_beta = 0.0\n",
        "\n",
        "print(\"precision: {:.5f}\".format(p), \n",
        "      \"recall: {:.5f}\".format(r), \n",
        "      \"F1: {:.5f}\".format(f_beta))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:0.8078357434155337\n",
            "Number incorrect:23136\n",
            "precision: 0.87558 recall: 0.89427 F1: 0.88482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot9U8G1jWEjO",
        "colab_type": "text"
      },
      "source": [
        "#### Performance on dev set\n",
        "\n",
        "We can also get a more detailed score (true positives, false positives, true negatives, false negatives) on the dev set and iterate on the generative training process if we need to"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFUbHlys9M4x",
        "colab_type": "code",
        "outputId": "e9a0184f-32e9-4e3c-b134-a4361f6f4cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "L_dev = labeler.apply(split=1)\n",
        "tp, fp, tn, fn = gen_model.error_analysis(session, L_dev, dev_cand_labels)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clearing existing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 27/15050 [00:00<00:56, 266.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running UDF...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 15050/15050 [00:58<00:00, 258.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Scores (Un-adjusted)\n",
            "========================================\n",
            "Pos. class accuracy: 0.901\n",
            "Neg. class accuracy: 0.728\n",
            "Precision            0.855\n",
            "Recall               0.901\n",
            "F1                   0.877\n",
            "----------------------------------------\n",
            "TP: 8675 | FP: 1473 | TN: 3946 | FN: 956\n",
            "========================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1w-dKHZ8TMF",
        "colab_type": "text"
      },
      "source": [
        "Saving the predictions of the generative model on the train set back to the database for future use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yNNLBQ89vVZ",
        "colab_type": "code",
        "outputId": "a71d60bc-c77e-42b6-9c3e-158ad35cc006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "save_marginals(session, L_train, train_marginals)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved 120397 marginals\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEUbvftvWOII",
        "colab_type": "text"
      },
      "source": [
        "## Training a *noise-aware* discriminative model\n",
        "\n",
        "In this step we set up a noise-aware discriminative model in TensorFlow and see how close we come to the fully supervised version!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKSfYJpknSCL",
        "colab_type": "text"
      },
      "source": [
        "### First, load the candidates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO3eCdQp924i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cands = session.query(Narrative).filter(Narrative.split == 0).order_by(Narrative.id).all()\n",
        "dev_cands   = session.query(Narrative).filter(Narrative.split == 1).order_by(Narrative.id).all()\n",
        "test_cands  = session.query(Narrative).filter(Narrative.split == 2).order_by(Narrative.id).all()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msbrZQc_noPo",
        "colab_type": "text"
      },
      "source": [
        "### Train model using RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSAjjnerWX6U",
        "colab_type": "text"
      },
      "source": [
        "We decided to leverage Snorkel's built-in discriminative classifier and made some custom changes to work with our example. \n",
        "\n",
        "Note, how the number of training samples below are lower than what's present in the training set, it excludes samples where there was no LF coverage, that is it trains on train_marginals.shape[0] - (train_marginals == 0.5).sum() samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvoqgKfq932D",
        "colab_type": "code",
        "outputId": "32eaa31d-7e52-448d-cafd-e5f58b13ee61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "train_kwargs = {\n",
        "    'lr':         0.01,\n",
        "    'dim':        100,\n",
        "    'n_epochs':   10,\n",
        "    'dropout':    0.2,\n",
        "    'print_freq': 1,\n",
        "    'seed': 123,\n",
        "    'batch_size': 200,\n",
        "    'max_sentence_length': 512,\n",
        "    'vocab_size': 5000\n",
        "}\n",
        "\n",
        "lstm = TextRNN(seed=123, cardinality=Narrative.cardinality)\n",
        "# Note: Y_train are the marginals but Y_dev are the gold/ ground truth labels\n",
        "lstm.train(X_train=train_cands, Y_train=train_marginals, X_dev=dev_cands, \n",
        "           Y_dev=dev_cand_labels, **train_kwargs)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max sentence len in training data:  5729\n",
            "but capped to:  512\n",
            "And also curtailing warning(s) related to checking individual max sentence lengths in each narrative\n",
            "currrent vocab size is:  170265\n",
            "but capped to:  5000\n",
            "[TextRNN] Training model\n",
            "[TextRNN] n_train=109706  #epochs=10  batch size=200\n",
            "[TextRNN] Epoch 0 (468.12s)\tAverage loss=0.442568\tDev F1=90.83\n",
            "[TextRNN] Epoch 1 (964.29s)\tAverage loss=0.399934\tDev F1=91.14\n",
            "[TextRNN] Epoch 2 (1470.67s)\tAverage loss=0.395937\tDev F1=90.66\n",
            "[TextRNN] Epoch 3 (1968.91s)\tAverage loss=0.394322\tDev F1=90.20\n",
            "[TextRNN] Epoch 4 (2464.33s)\tAverage loss=0.393556\tDev F1=90.14\n",
            "[TextRNN] Epoch 5 (2956.59s)\tAverage loss=0.392860\tDev F1=89.59\n",
            "[TextRNN] Epoch 6 (3448.02s)\tAverage loss=0.392751\tDev F1=90.42\n",
            "[TextRNN] Epoch 7 (3938.71s)\tAverage loss=0.392483\tDev F1=90.96\n",
            "[TextRNN] Epoch 8 (4431.30s)\tAverage loss=0.392119\tDev F1=90.41\n",
            "[TextRNN] Model saved as <TextRNN>\n",
            "[TextRNN] Epoch 9 (4925.70s)\tAverage loss=0.392195\tDev F1=90.76\n",
            "[TextRNN] Model saved as <TextRNN>\n",
            "[TextRNN] Training done (4952.33s)\n",
            "currrent vocab size is:  170265\n",
            "but capped to:  5000\n",
            "[TextRNN] Loaded model <TextRNN>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-wA6gEfWhl1",
        "colab_type": "text"
      },
      "source": [
        "### Accuracies on dev and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZBYLyyW-LdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cff9dde-53c4-4c4a-f392-6b5de34f6efd"
      },
      "source": [
        "accuracy_dev = lstm.score(dev_cands, dev_cand_labels, batch_size=200)\n",
        "print(\"precision: {:.5f}\".format(accuracy_dev[0]), \n",
        "      \"recall: {:.5f}\".format(accuracy_dev[1]), \n",
        "      \"F1: {:.5f}\".format(accuracy_dev[2]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision: 0.85768 recall: 0.96366 F1: 0.90759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlC3vfgA-Nse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75cc507d-4cc9-4bfe-a60c-1853a6662be4"
      },
      "source": [
        "accuracy_test = lstm.score(test_cands, test_cand_labels, batch_size=200)\n",
        "print(\"precision: {:.5f}\".format(accuracy_test[0]), \n",
        "      \"recall: {:.5f}\".format(accuracy_test[1]), \n",
        "      \"F1: {:.5f}\".format(accuracy_test[2]))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision: 0.86330 recall: 0.96787 F1: 0.91260\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}