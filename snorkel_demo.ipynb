{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snorkel-demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fastforwardlabs/snorkel-demo-colab/blob/master/snorkel_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2hgkWoEUODX",
        "colab_type": "text"
      },
      "source": [
        "# Training a text classification model using noisy regular expressions\n",
        "\n",
        "In this notebook we will walk through a simple text classification problem that trains a complaint classifier using data from [Consumer Financial Protection Bureau](https://www.consumerfinance.gov/data-research/consumer-complaints/), showing how to use Snorkel for weak supervision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaf5CrXPsVOI",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n13vH4IdX2N5",
        "colab_type": "text"
      },
      "source": [
        "Installing Snorkel and other required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q40cmhf21u79",
        "colab_type": "code",
        "outputId": "ac4a3c34-8fbe-40c8-87a8-940512c03f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install -r requirements.txt\n",
        "!pip3 install git+https://github.com/nishamuktewar/snorkel\n",
        "!pip3 install treedlib\n",
        "!pip3 install numbskull"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4==4.7.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (4.7.1)\n",
            "Requirement already satisfied: future==0.17.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.17.1)\n",
            "Requirement already satisfied: ipywidgets==7.4.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (7.4.2)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: lxml==4.3.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (4.3.3)\n",
            "Requirement already satisfied: matplotlib==3.0.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (3.0.1)\n",
            "Requirement already satisfied: nltk==3.2.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.2.5)\n",
            "Requirement already satisfied: numba==0.43.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.43.1)\n",
            "Requirement already satisfied: numpy==1.16.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (1.16.1)\n",
            "Requirement already satisfied: pandas==0.24.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.24.2)\n",
            "Requirement already satisfied: py4j==0.10.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (0.10.8.1)\n",
            "Requirement already satisfied: requests==2.22.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (2.22.0)\n",
            "Requirement already satisfied: runipy==0.1.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 13)) (0.1.5)\n",
            "Requirement already satisfied: scipy==1.2.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 14)) (1.2.1)\n",
            "Requirement already satisfied: six==1.12.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 15)) (1.12.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 16)) (2.1.4)\n",
            "Requirement already satisfied: sqlalchemy==1.3.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 17)) (1.3.3)\n",
            "Requirement already satisfied: tika==1.19 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 18)) (1.19)\n",
            "Requirement already satisfied: tqdm==4.32.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 19)) (4.32.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 20)) (0.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.6/dist-packages (from beautifulsoup4==4.7.1->-r requirements.txt (line 1)) (1.9.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.4.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.3.2)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.6.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 4)) (4.5.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 4)) (5.5.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 4)) (6.0.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 4)) (5.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r requirements.txt (line 6)) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r requirements.txt (line 6)) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: llvmlite>=0.28.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba==0.43.1->-r requirements.txt (line 8)) (0.29.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->-r requirements.txt (line 10)) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 12)) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 12)) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 12)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: pyzmq>=14.1.0 in /usr/local/lib/python3.6/dist-packages (from runipy==0.1.5->-r requirements.txt (line 13)) (17.0.0)\n",
            "Requirement already satisfied: Pygments>=1.6 in /usr/local/lib/python3.6/dist-packages (from runipy==0.1.5->-r requirements.txt (line 13)) (2.1.3)\n",
            "Requirement already satisfied: Jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from runipy==0.1.5->-r requirements.txt (line 13)) (2.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (2.0.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (0.9.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (0.2.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (0.0.7)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (2.6.0)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (2.0.1)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (7.0.4)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (0.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tika==1.19->-r requirements.txt (line 18)) (41.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r requirements.txt (line 20)) (0.21.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (1.0.16)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.7.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.5.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.4.2->-r requirements.txt (line 3)) (5.2.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 4)) (0.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7.2->runipy==0.1.5->-r requirements.txt (line 13)) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 20)) (0.13.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.1.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.5.1)\n",
            "Collecting git+https://github.com/nishamuktewar/snorkel\n",
            "  Cloning https://github.com/nishamuktewar/snorkel to /tmp/pip-req-build-fynpchmn\n",
            "  Running command git clone -q https://github.com/nishamuktewar/snorkel /tmp/pip-req-build-fynpchmn\n",
            "Requirement already satisfied (use --upgrade to upgrade): snorkel==0.7.0b0 from git+https://github.com/nishamuktewar/snorkel in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: snorkel\n",
            "  Building wheel for snorkel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w3lajdz9/wheels/1c/dc/7b/9cf55b0576fad8e74e4e4c004231d1fd2814b01915d5582ba2\n",
            "Successfully built snorkel\n",
            "Requirement already satisfied: treedlib in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from treedlib) (4.3.3)\n",
            "Requirement already satisfied: numbskull in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from numbskull) (0.17.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyPnpQ6t1-D-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNCpKXv1uwfz",
        "colab_type": "text"
      },
      "source": [
        "Disabling warning messages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf-MTJzpuTpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ongFEcu9YhSC",
        "colab_type": "text"
      },
      "source": [
        "Loading necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnphVByC2D4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import sklearn\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from snorkel import SnorkelSession\n",
        "from snorkel.models import candidate_subclass, Context, Candidate, StableLabel\n",
        "from snorkel.contrib.models.text import RawText\n",
        "from snorkel.annotations import LabelAnnotator\n",
        "from snorkel.learning import GenerativeModel\n",
        "from snorkel.annotations import save_marginals\n",
        "from snorkel.learning.tensorflow import TextRNN\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2zUynbBUfV0",
        "colab_type": "text"
      },
      "source": [
        "## Download data, if it doesn't *exist*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1TWYOoI2Tnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"./data\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "    !curl https://data.consumerfinance.gov/api/views/s6ew-h6mp/rows.csv?accessType=DOWNLOAD > ./data/complaints.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS5CHRYDUmfW",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing\n",
        "Data load, filtering out irrelevant fields and rows. Each row in the final dataframe - complaints_df consists of a \"complaint\" field and an associated ground truth label = (1, -1). These ground truth labels are used to review the performance of the labeling process, afterall the whole idea is to do without any labeled data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7govEII2gM3",
        "colab_type": "code",
        "outputId": "9e06e8fb-0582-4a9d-df55-d9f862827cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "complaints = pd.read_csv(os.path.join(data_dir,'complaints.csv'))\n",
        "complaints.info()\n",
        "complaints.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5,6,11,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1322633 entries, 0 to 1322632\n",
            "Data columns (total 18 columns):\n",
            "Date received                   1322633 non-null object\n",
            "Product                         1322633 non-null object\n",
            "Sub-product                     1087467 non-null object\n",
            "Issue                           1322633 non-null object\n",
            "Sub-issue                       786560 non-null object\n",
            "Consumer complaint narrative    393129 non-null object\n",
            "Company public response         470468 non-null object\n",
            "Company                         1322633 non-null object\n",
            "State                           1301875 non-null object\n",
            "ZIP code                        1201781 non-null object\n",
            "Tags                            181027 non-null object\n",
            "Consumer consent provided?      715628 non-null object\n",
            "Submitted via                   1322633 non-null object\n",
            "Date sent to company            1322633 non-null object\n",
            "Company response to consumer    1322626 non-null object\n",
            "Timely response?                1322633 non-null object\n",
            "Consumer disputed?              768501 non-null object\n",
            "Complaint ID                    1322633 non-null int64\n",
            "dtypes: int64(1), object(17)\n",
            "memory usage: 181.6+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1322633, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gwjyL9jUz48",
        "colab_type": "text"
      },
      "source": [
        "### Subset data to include products with narrative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BcTLpTu2iV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "products_w_narrative = complaints[complaints['Product'].notnull() & \n",
        "                                  complaints['Consumer complaint narrative'].notnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aswvj9bu2mJt",
        "colab_type": "code",
        "outputId": "e1e187c1-65b8-4062-c559-fa39d103f3b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "print(products_w_narrative['Product'].unique())\n",
        "print(products_w_narrative['Product'].value_counts())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Credit reporting, credit repair services, or other personal consumer reports'\n",
            " 'Debt collection' 'Credit card or prepaid card'\n",
            " 'Payday loan, title loan, or personal loan' 'Mortgage' 'Student loan'\n",
            " 'Money transfer, virtual currency, or money service'\n",
            " 'Checking or savings account' 'Vehicle loan or lease' 'Credit card'\n",
            " 'Bank account or service' 'Credit reporting' 'Consumer Loan'\n",
            " 'Prepaid card' 'Payday loan' 'Money transfers' 'Other financial service'\n",
            " 'Virtual currency']\n",
            "Credit reporting, credit repair services, or other personal consumer reports    96556\n",
            "Debt collection                                                                 88641\n",
            "Mortgage                                                                        53776\n",
            "Credit reporting                                                                31588\n",
            "Credit card or prepaid card                                                     22389\n",
            "Student loan                                                                    22240\n",
            "Credit card                                                                     18838\n",
            "Bank account or service                                                         14885\n",
            "Checking or savings account                                                     13476\n",
            "Consumer Loan                                                                    9474\n",
            "Vehicle loan or lease                                                            5975\n",
            "Money transfer, virtual currency, or money service                               5670\n",
            "Payday loan, title loan, or personal loan                                        4619\n",
            "Payday loan                                                                      1747\n",
            "Money transfers                                                                  1497\n",
            "Prepaid card                                                                     1450\n",
            "Other financial service                                                           292\n",
            "Virtual currency                                                                   16\n",
            "Name: Product, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJPUhu9ucDMC",
        "colab_type": "text"
      },
      "source": [
        "### Selects two types of products - credit reporting and mortgage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGAhdow-2oT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# credit reporting only\n",
        "credit_reporting = products_w_narrative[products_w_narrative['Product'] == 'Credit reporting, ' + \n",
        "                                 'credit repair services, or other personal consumer reports']\n",
        "# mortgage only\n",
        "mortgage = products_w_narrative[products_w_narrative['Product'] == 'Mortgage']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT9hYjQD2qvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "credit_narrative = credit_reporting['Consumer complaint narrative'].values\n",
        "positive_labels = pd.Series(np.ones(credit_narrative.shape[0]))\n",
        "positive_df = pd.DataFrame({'complaint': credit_narrative, 'label': positive_labels})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev-bLnW02skW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mortgage_narrative = mortgage['Consumer complaint narrative'].values\n",
        "negative_labels = pd.Series(np.full(mortgage_narrative.shape[0], -1))\n",
        "negative_df = pd.DataFrame({'complaint': mortgage_narrative, 'label': negative_labels})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2MfDm0XU8H5",
        "colab_type": "text"
      },
      "source": [
        "### Combine into one dataframe, create labels \n",
        "(1 for credit reporting, -1 for mortgage)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZZP4-on2ukd",
        "colab_type": "code",
        "outputId": "2c3b96e8-e208-4a00-8a46-6ca306f4ba61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "complaints_df = pd.concat([positive_df, negative_df], ignore_index=True)\n",
        "complaints_df.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150332, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rX87qAw2wvc",
        "colab_type": "code",
        "outputId": "e01c1c45-abdd-4cbd-a113-820501be95f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "complaints_df['label'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1.0    96556\n",
              "-1.0    53776\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rJlMTGxVDPE",
        "colab_type": "text"
      },
      "source": [
        "### Split data into train, dev, test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkY-5o7D2zFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, testval = train_test_split(complaints_df, test_size=0.2, random_state=123)\n",
        "dev, test = train_test_split(testval, test_size=0.5, random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kv7_632VFL3",
        "colab_type": "text"
      },
      "source": [
        "## Create noisy labeling functions\n",
        "\n",
        "Our assumption is that we don't have the ground truth labels for our data, but instead have these noisy and possibly conflicting labels based on regular expressions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjA7CEoUci2C",
        "colab_type": "text"
      },
      "source": [
        "### Regular expressions that define words, phrases, actions for use in labeling functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i70mzuQ421Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AGENCY_NAMES = r'\\bexperian\\b|\\btransunion\\b|\\bequifax\\b|\\bfcra\\b'   \n",
        "DEBT_MENTIONS = r'\\bcollector\\b|\\bdebt\\b|\\bcreditor\\b'\n",
        "ADDRESS_MENTIONS = r'\\baddress\\b'\n",
        "DESCRIPTIONS = r'\\binaccura|\\bcompromise'\n",
        "IDENTITY = r'\\bidentity'\n",
        "CREDIT_REPORT_MENTIONS = r'\\bcredit (report|agency|reporting|bureau|agencies)'              \n",
        "MORTGAGE_MENTIONS = r'\\bloan\\b|\\bmortgage\\|\\bprepayment\\b|\\bprincipal\\b|\\binterest\\b|\\bescrow\\b'\n",
        "CHECKS = r'\\bcheck'\n",
        "TAXES = r'\\btax'\n",
        "LEASE = r'\\blease'\n",
        "HOUSE_MENTIONS = r'\\bhouse\\b|\\bhome\\bcondo\\b'\n",
        "MORTGAGE_HELP_ACTIONS = r'\\bmitigat|\\bmodifi\\brefinanc'\n",
        "MORTGAGE_COMPONENTS = r'\\bequity\\b|\\bdownpayment\\b|\\bshortage\\b'\n",
        "POSITIVE_ACTIONS = r'\\bremov|\\bdispute\\b' \n",
        "INQUIRY_ACTIONS  = r'\\binquir\\b|\\berror\\b'\n",
        "NEGATIVE_ACTIONS = r'\\bpredator|\\bapprove|\\bservic|\\bappraise|\\bforeclos'  \n",
        "                                                                      \n",
        "FRAUD = r'\\bfraudulent (account|charges)'                                               \n",
        "MONEYXFER = r'\\bmoney transfer'                                                         \n",
        "CREDIT_REPORTING = r'\\b(identity has been compromise(|d)|data breaches|inquiries to bus\\\n",
        "inesses|mistakes appear in my report|reporting incorrectly|dispute(|d)|(t|T)ransunion|derog\\\n",
        "atory|experian|identity theft)'                                                             \n",
        "CREDIT_REPAIR = r'\\b(credit repair|hard inquiry|inquiries to businesses|mistakes appear\\\n",
        " in my report|reporting incorrectly)'       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQzYfavwdWad",
        "colab_type": "text"
      },
      "source": [
        "### Labeling functions that help provide weak supervision\n",
        "\n",
        "In other words, instead of hand-labeling data to create a training set for our model, we write functions that look something like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0a_eu1223tT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lf_agency_names(complaint):                                                                   \n",
        "    if re.search(AGENCY_NAMES, str(complaint), re.IGNORECASE):                            \n",
        "        return 1                                                                            \n",
        "    else:                                                                                   \n",
        "        return 0            \n",
        "\n",
        "def lf_debt(complaint):                                                            \n",
        "    if re.search(DEBT_MENTIONS, str(complaint), re.IGNORECASE):                           \n",
        "        return 1                                                                            \n",
        "    else:                                                                                   \n",
        "        return 0      \n",
        "\n",
        "def lf_address(complaint):                                                            \n",
        "    if re.search(ADDRESS_MENTIONS, str(complaint), re.IGNORECASE):\n",
        "        return 1                                                                            \n",
        "    else:                                                                                   \n",
        "        return 0     \n",
        "    \n",
        "def lf_credit_report(complaint):                                                           \n",
        "    if re.search(CREDIT_REPORT_MENTIONS, str(complaint), re.IGNORECASE):                          \n",
        "        return 1                                                                            \n",
        "    else:                                                                                   \n",
        "        return 0             \n",
        "    \n",
        "def lf_credit_actions(complaint):                                                           \n",
        "    if re.search(POSITIVE_ACTIONS, str(complaint), re.IGNORECASE):                          \n",
        "        return 1                                                                            \n",
        "    else:                                                                                   \n",
        "        return 0             \n",
        "    \n",
        "def lf_mortgage(complaint):                                                                 \n",
        "    if re.search(MORTGAGE_MENTIONS, str(complaint), re.IGNORECASE):                            \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0        \n",
        "    \n",
        "def lf_inquiry(complaint):                                                                 \n",
        "    if re.search(INQUIRY_ACTIONS, str(complaint), re.IGNORECASE):                            \n",
        "        return 1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0        \n",
        "    \n",
        "def lf_house_mentions(complaint):                                                         \n",
        "    if re.search(HOUSE_MENTIONS, str(complaint), re.IGNORECASE):                          \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0          \n",
        "    \n",
        "def lf_mortgage_help(complaint):                                                         \n",
        "    if re.search(MORTGAGE_HELP_ACTIONS, str(complaint), re.IGNORECASE):                          \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0          \n",
        "    \n",
        "def lf_mortgage_components(complaint):                                                         \n",
        "    if re.search(MORTGAGE_COMPONENTS, str(complaint), re.IGNORECASE):                          \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0          \n",
        "    \n",
        "def lf_fraud(complaint):                                                                    \n",
        "    if (re.search(FRAUD, str(complaint), re.IGNORECASE)                                     \n",
        "        and not re.search(MONEYXFER, str(complaint), re.IGNORECASE)):                       \n",
        "        return 1                                                                            \n",
        "    elif (re.search(FRAUD, str(complaint), re.IGNORECASE)                                   \n",
        "          and re.search(MONEYXFER, str(complaint), re.IGNORECASE)):                         \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0     \n",
        "    \n",
        "def lf_reporting(complaint):                                                                \n",
        "    if (re.search(CREDIT_REPORTING, str(complaint), re.IGNORECASE)                          \n",
        "        and not re.search(MONEYXFER, str(complaint), re.IGNORECASE)):                       \n",
        "        return 1                                                                            \n",
        "    elif (re.search(CREDIT_REPORTING, str(complaint), re.IGNORECASE)                        \n",
        "           and re.search(MONEYXFER, str(complaint), re.IGNORECASE)):                        \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0     \n",
        "\n",
        "def lf_repair(complaint):                                                                   \n",
        "    if (re.search(CREDIT_REPAIR, str(complaint), re.IGNORECASE)                             \n",
        "        and not re.search(MONEYXFER, str(complaint), re.IGNORECASE)                         \n",
        "        and not re.search(CREDIT_REPORTING, str(complaint), re.IGNORECASE)                  \n",
        "       ):                                                                                   \n",
        "        return 1                                                                            \n",
        "    elif ((re.search(CREDIT_REPAIR, str(complaint), re.IGNORECASE)                          \n",
        "           and re.search(MONEYXFER, str(complaint), re.IGNORECASE))                         \n",
        "          or                                                                                \n",
        "          (re.search(CREDIT_REPAIR, str(complaint), re.IGNORECASE)                          \n",
        "           and re.search(CREDIT_REPORTING, str(complaint), re.IGNORECASE))                  \n",
        "         ):                                                                                 \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0  \n",
        "\n",
        "def lf_credit_description(complaint):                                                                \n",
        "    if (re.search(DESCRIPTIONS, str(complaint), re.IGNORECASE)                          \n",
        "        and re.search(IDENTITY, str(complaint), re.IGNORECASE)):                       \n",
        "        return 1                                                                                                                                             \n",
        "    else:                                                                                   \n",
        "        return 0           \n",
        "    \n",
        "def lf_description_not_mortgage(complaint):                                                                \n",
        "    if (re.search(DESCRIPTIONS, str(complaint), re.IGNORECASE)                          \n",
        "        and not re.search(MORTGAGE_MENTIONS, str(complaint), re.IGNORECASE)):                       \n",
        "        return 1                                                                                                                                             \n",
        "    else:                                                                                   \n",
        "        return 0           \n",
        "    \n",
        "def lf_tax(complaint):                                                         \n",
        "    if re.search(TAXES, str(complaint), re.IGNORECASE):                          \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0    \n",
        "    \n",
        "def lf_check(complaint):                                                         \n",
        "    if re.search(CHECKS, str(complaint), re.IGNORECASE):                          \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0    \n",
        "    \n",
        "def lf_lease(complaint):                                                         \n",
        "    if re.search(LEASE, str(complaint), re.IGNORECASE):                          \n",
        "        return 1                                                                          \n",
        "    else:                                                                                   \n",
        "        return 0    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_pBGXxdVTKV",
        "colab_type": "text"
      },
      "source": [
        "## Generate Snorkel objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1GW0OCXVUJi",
        "colab_type": "text"
      },
      "source": [
        "### Candidates\n",
        "\n",
        "Candidate objects in Snorkel represent objects to be classified. In this case we are interested in classifying whether a narrative is positive -that is credit related or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjVSxCjz26NK",
        "colab_type": "code",
        "outputId": "8e2d5d54-42a6-470b-ee5d-c43ec7e8724f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "session = SnorkelSession()\n",
        "\n",
        "values = list(complaints_df.label.unique())\n",
        "print(values)\n",
        "\n",
        "# snorkel candidate, value if none defaults to binary (true, false)\n",
        "Narrative = candidate_subclass('Narrative', ['narrative'], values=values)\n",
        "\n",
        "# Make sure DB is cleared\n",
        "session.query(Context).delete()\n",
        "session.query(Candidate).delete()\n",
        "session.query(StableLabel).delete()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, -1.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcRDtTkoViEb",
        "colab_type": "text"
      },
      "source": [
        "### Contexts\n",
        "\n",
        "All Candidate objects point to one or more Context objects representing the raw data that they are rooted in. In this case, our candidates will each point to a single Context object representing the raw text of the complaint.\n",
        "\n",
        "Once we have defined the Context for each Candidate, we can commit them to the database. Note that we also split into three sets while doing this:\n",
        "\n",
        "- Training set (split=0): The narratives for which we have noisy, conflicting labels from our labeling functions; we will resolve these conflicts using the GenerativeModel and then use them as training data for the RNN\n",
        "- Development set (split=1): We will pretend that we do not have any noisy, conflicting labels for this split of the data, and use these to test the RNN's performance on unseen data\n",
        "- Test set (split=2): We will pretend that we do not have any noisy, conflicting labels for this split of the data, and use these to test the RNN's performance on unseen data   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jypxk-b_3BAJ",
        "colab_type": "code",
        "outputId": "d59a57be-7643-402f-8647-dd74ec42bc47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_index = train.index\n",
        "train.index.str = np.asarray(str(x) for x in train.index)\n",
        "train_complaints = train.values[:, 0]\n",
        "train_labels = train.values[:, 1]\n",
        "\n",
        "for element in zip(train_index, train_complaints, train_labels):\n",
        "    split = 0\n",
        "    raw_text = RawText(stable_id=element[0], name=element[0], text=str(element[1]))\n",
        "    narrative = Narrative(narrative=raw_text, split=split)\n",
        "    session.add(narrative)\n",
        "\n",
        "dev_index = dev.index\n",
        "dev.index.str = np.asarray(str(x) for x in dev.index)\n",
        "dev_complaints = dev.values[:, 0]\n",
        "dev_labels = dev.values[:, 1]\n",
        "\n",
        "for element in zip(dev_index, dev_complaints, dev_labels):\n",
        "    split = 1\n",
        "    raw_text = RawText(stable_id=element[0], name=element[0], text=str(element[1]))\n",
        "    narrative = Narrative(narrative=raw_text, split=split)\n",
        "    session.add(narrative)\n",
        "\n",
        "test_index = test.index\n",
        "test.index.str = np.asarray(str(x) for x in test.index)\n",
        "test_complaints = test.values[:, 0]\n",
        "test_labels = test.values[:, 1]\n",
        "\n",
        "for element in zip(test_index, test_complaints, test_labels):\n",
        "    split = 2\n",
        "    raw_text = RawText(stable_id=element[0], name=element[0], text=str(element[1]))\n",
        "    narrative = Narrative(narrative=raw_text, split=split)\n",
        "    session.add(narrative)\n",
        "\n",
        "session.commit()\n",
        "\n",
        "# number of datapoints\n",
        "print(\"number of datapoints in candidate: \", session.query(Narrative).count())\n",
        "# load ground truth labels\n",
        "train_cand_labels = train_labels\n",
        "dev_cand_labels = dev_labels\n",
        "test_cand_labels = test_labels"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of datapoints in candidate:  150332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8--icqpq3JuM",
        "colab_type": "code",
        "outputId": "2c41e749-a83b-4211-e41a-f85d6bc3eac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# test one labeling function\n",
        "labeled = []\n",
        "for c in session.query(Narrative).filter(Narrative.split == 1).all():\n",
        "    if lf_tax(c) != 0:\n",
        "        labeled.append(c)\n",
        "print(\"Number labeled:\", len(labeled))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number labeled: 904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpOVOJiKVoSn",
        "colab_type": "text"
      },
      "source": [
        "### Labels\n",
        "\n",
        "Next, we assign labeling functions for each of the training candidates in a sparse matrix (which will also automatically be saved to the Snorkel database), with one row for each candidate and one column for each label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQnhzeaf3nrt",
        "colab_type": "code",
        "outputId": "3e443be7-5f2f-4baf-d638-1db34f1348fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "LFs = [lf_agency_names, lf_debt, lf_address, lf_credit_report, lf_credit_actions, \n",
        "       lf_inquiry, lf_mortgage, lf_house_mentions, lf_mortgage_components,\n",
        "       lf_mortgage_help, lf_fraud, lf_reporting, lf_repair,\n",
        "       lf_credit_description, lf_description_not_mortgage,\n",
        "       lf_tax, lf_check, lf_lease]\n",
        "# apply labeling functions\n",
        "labeler = LabelAnnotator(lfs = LFs)\n",
        "L_train = labeler.apply(split=0)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 18/120265 [00:00<11:22, 176.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Clearing existing...\n",
            "Running UDF...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 120265/120265 [10:20<00:00, 193.78it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCtH_AV-3scM",
        "colab_type": "code",
        "outputId": "339a4e65-1594-4f4d-c5b1-984e07ccd81f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "# see what's going on\n",
        "print(L_train.get_candidate(session, 0))\n",
        "print(L_train.get_key(session, 0))\n",
        "print(L_train.lf_stats(session))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Narrative(Raw Text I had a XXXX XXXX card back in XXXX. I set up the account via their phone service after starting the card in store. When I went to pay a bill, the sum initially showed deducted from my checking account and then reappeared after a few weeks. It turned out, the XXXX XXXX  representative. Seeing as this was their error, they corrected the information and removed the late fee. \n",
            "\n",
            "Now, just over 2 years later, I am attempting to by a home and that error ( which XXXX XXXX  said was being removed ) is still on my credit record. I even closed that account over a year ago. \n",
            "\n",
            "I would like this error removed from my credit history, not just a late fee removed.)\n",
            "LabelKey (lf_agency_names)\n",
            "                              j  Coverage  Overlaps  Conflicts\n",
            "lf_agency_names               0  0.280148  0.262096   0.062121\n",
            "lf_debt                       1  0.144631  0.137264   0.057456\n",
            "lf_address                    2  0.099173  0.093818   0.046905\n",
            "lf_credit_report              3  0.438548  0.396000   0.141388\n",
            "lf_credit_actions             4  0.329007  0.313474   0.110223\n",
            "lf_inquiry                    5  0.061298  0.058562   0.035638\n",
            "lf_mortgage                   6  0.354542  0.261797   0.179246\n",
            "lf_house_mentions             7  0.081844  0.073662   0.037501\n",
            "lf_mortgage_components        8  0.031996  0.030807   0.015191\n",
            "lf_mortgage_help              9  0.013520  0.011882   0.005920\n",
            "lf_fraud                     10  0.021195  0.020471   0.004108\n",
            "lf_reporting                 11  0.325024  0.318023   0.100769\n",
            "lf_repair                    12  0.027847  0.026259   0.019881\n",
            "lf_credit_description        13  0.012971  0.012971   0.002952\n",
            "lf_description_not_mortgage  14  0.078277  0.074643   0.009579\n",
            "lf_tax                       15  0.065979  0.062869   0.033227\n",
            "lf_check                     16  0.123669  0.112360   0.079741\n",
            "lf_lease                     17  0.010394  0.009720   0.005779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6CcudVdVvxk",
        "colab_type": "text"
      },
      "source": [
        "## Training generative model\n",
        "\n",
        "\n",
        "The problem with the above labeling functions is that they're noisy, conflicting and may even overlap on certain examples. The key technical idea of Snorkel's generative modeling approach is that we can automatically model and denoise them!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbo3wzLj5ukd",
        "colab_type": "code",
        "outputId": "2dae0294-3940-40b0-9019-cf836a29e57f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gen_model = GenerativeModel()\n",
        "gen_model.train(L_train, epochs=20, decay=0.95, step_size=0.1/L_train.shape[0], reg_param=1e-6)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inferred cardinality: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XgNEwhsV31e",
        "colab_type": "text"
      },
      "source": [
        "## Applying the generative model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiKU0A_2gjZU",
        "colab_type": "text"
      },
      "source": [
        "### Probabilistic Label Statistics\n",
        "\n",
        "We view the distribution of weak labels produced by our generative model. Note that the samples in the 0.5 bucket indicate the ones that have no LF coverage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7-pU4eS5_Na",
        "colab_type": "code",
        "outputId": "0c4965c3-03ff-4a38-b042-445ba3f70226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "train_marginals = gen_model.marginals(L_train)\n",
        "plt.hist(train_marginals, bins=20)\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tteWMMziXPx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3eda395-90b5-44b4-c2c7-fc39e952616f"
      },
      "source": [
        "print(\"So we have \", (train_marginals == 0.5).sum(), \" samples where the LFs do not provide any coverage!\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "So we have  10658  samples where the LFs do not provide any coverage!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok4sbNTljlQ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f725011-63cc-4150-a363-1624aad7d0b2"
      },
      "source": [
        "train_marginals.shape[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUb6eaA4jsip",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "afb306eb-b8e9-4e11-ff23-cd4e8a454aa1"
      },
      "source": [
        "(train_marginals == 0.5).sum()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10658"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdSWOLOHV8xM",
        "colab_type": "text"
      },
      "source": [
        "### Compare learned accuracies vs empirical accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BJFOfWVjNjf",
        "colab_type": "text"
      },
      "source": [
        "#### Learned accuracies from our generative model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu6pQmGf8a60",
        "colab_type": "code",
        "outputId": "12b35c0f-3ed4-4220-d334-6cf9acf46cb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy = gen_model.score(L_train, train_cand_labels)\n",
        "print(\"precision: {:.5f}\".format(accuracy[0]), \n",
        "      \"recall: {:.5f}\".format(accuracy[1]), \n",
        "      \"F-beta: {:.5f}\".format(accuracy[2]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision: 0.86024 recall: 0.90166 F-beta: 0.88047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbPGL0eikcX1",
        "colab_type": "text"
      },
      "source": [
        "#### Empirical accuracies of our labeling functions - majority vote\n",
        "\n",
        "We observe that the majority vote approach does almost as well as teh generative model for our use case!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAHOrwAi8wia",
        "colab_type": "code",
        "outputId": "1a18d1ee-5bab-43f1-9d9a-3d94c0be1444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Collect the majority vote answer for each complaint\n",
        "mv = []\n",
        "for i in range(L_train.shape[0]):\n",
        "    if np.diff(L_train[i].indptr) != 0:   #indicates that there is no coverage for a particular datapoint\n",
        "        c = Counter([L_train[i,j] for j in L_train[i].nonzero()[1]])\n",
        "        mv.append(c.most_common(1)[0][0])\n",
        "    else:\n",
        "        mv.append(0) # assume that no label is equivalent to a negative example\n",
        "mv = np.array(mv)\n",
        "\n",
        "# Count the number correct by majority vote\n",
        "n_correct = np.sum([1 for i in range(L_train.shape[0]) if mv[i] == train_cand_labels[i]])\n",
        "print (\"Accuracy:{}\".format(n_correct / float(L_train.shape[0])))\n",
        "print (\"Number incorrect:{}\".format(L_train.shape[0] - n_correct))\n",
        "\n",
        "# Compute and return precision, recall\n",
        "tp = (0.5 * (mv * train_cand_labels + 1))[mv == 1].sum()\n",
        "pred_pos = mv[mv == 1].sum()\n",
        "p = tp / float(pred_pos) if pred_pos > 0 else 0.0\n",
        "pos = train_cand_labels[train_cand_labels == 1].sum()\n",
        "r = tp / float(pos) if pos > 0 else 0.0\n",
        "\n",
        "# Compute general F-beta score\n",
        "beta=1\n",
        "if p + r > 0:\n",
        "    f_beta = (1 + beta**2) * ((p * r) / (((beta**2) * p) + r))\n",
        "else:\n",
        "    f_beta = 0.0\n",
        "\n",
        "print(\"precision: {:.5f}\".format(p), \n",
        "      \"recall: {:.5f}\".format(r), \n",
        "      \"F-beta: {:.5f}\".format(f_beta))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:0.8077911279258304\n",
            "Number incorrect:23116\n",
            "precision: 0.87489 recall: 0.89429 F-beta: 0.88448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot9U8G1jWEjO",
        "colab_type": "text"
      },
      "source": [
        "#### Performance on dev set\n",
        "We can also get a more detailed score (true positives, false positives, true negatives, false negatives) on the dev set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFUbHlys9M4x",
        "colab_type": "code",
        "outputId": "090a53fb-9d95-46e1-89bf-3d5bcfcbac1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "L_dev = labeler.apply(split=1)\n",
        "tp, fp, tn, fn = gen_model.error_analysis(session, L_dev, dev_cand_labels)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clearing existing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 20/15033 [00:00<01:16, 195.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running UDF...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 15033/15033 [01:19<00:00, 189.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Scores (Un-adjusted)\n",
            "========================================\n",
            "Pos. class accuracy: 0.906\n",
            "Neg. class accuracy: 0.735\n",
            "Precision            0.865\n",
            "Recall               0.906\n",
            "F1                   0.885\n",
            "----------------------------------------\n",
            "TP: 8874 | FP: 1390 | TN: 3849 | FN: 920\n",
            "========================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1w-dKHZ8TMF",
        "colab_type": "text"
      },
      "source": [
        "Saving the predictions of the generative model on the train set back to the database for future use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yNNLBQ89vVZ",
        "colab_type": "code",
        "outputId": "a255331b-ce36-4b2c-cfa1-5709e4e698d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "save_marginals(session, L_train, train_marginals)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved 120265 marginals\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEUbvftvWOII",
        "colab_type": "text"
      },
      "source": [
        "## Training a *noise-aware* discriminative model\n",
        "\n",
        "In this step we set up a noise-aware discriminative model in TensorFlow and see how close we come to the fully supervised version!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKSfYJpknSCL",
        "colab_type": "text"
      },
      "source": [
        "### First, load the candidates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO3eCdQp924i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cands = session.query(Narrative).filter(Narrative.split == 0).order_by(Narrative.id).all()\n",
        "dev_cands   = session.query(Narrative).filter(Narrative.split == 1).order_by(Narrative.id).all()\n",
        "test_cands  = session.query(Narrative).filter(Narrative.split == 2).order_by(Narrative.id).all()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msbrZQc_noPo",
        "colab_type": "text"
      },
      "source": [
        "### Train model using RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSAjjnerWX6U",
        "colab_type": "text"
      },
      "source": [
        "We decided to leverage Snorkel's built-in discriminative classifier and made some custom changes to work with our example. \n",
        "\n",
        "Note, how the number of training samples below are lower than what's present in the training set, it excludes samples where there was no LF coverage, that is it trains on train_marginals.shape[0] - (train_marginals == 0.5).sum() samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvoqgKfq932D",
        "colab_type": "code",
        "outputId": "25ec1079-eae3-43da-881b-e140002443cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "train_kwargs = {\n",
        "    'lr':         0.01,\n",
        "    'dim':        100,\n",
        "    'n_epochs':   10,\n",
        "    'dropout':    0.2,\n",
        "    'print_freq': 1,\n",
        "    'seed': 123,\n",
        "    'batch_size': 200,\n",
        "    'max_sentence_length': 512,\n",
        "    'vocab_size': 5000\n",
        "}\n",
        "\n",
        "lstm = TextRNN(seed=123, cardinality=Narrative.cardinality)\n",
        "# Note: Y_train are the marginals but Y_dev are the gold/ ground truth labels\n",
        "lstm.train(X_train=train_cands, Y_train=train_marginals, X_dev=dev_cands, Y_dev=dev_cand_labels, **train_kwargs)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max sentence len in training data:  5729\n",
            "but capped to:  512\n",
            "And also curtailing warning(s) related to checking individual max sentence lengths in each narrative\n",
            "currrent vocab size is:  170119\n",
            "but capped to:  5000\n",
            "[TextRNN] Training model\n",
            "[TextRNN] n_train=109607  #epochs=10  batch size=200\n",
            "[TextRNN] Epoch 0 (734.95s)\tAverage loss=0.452717\tDev F1=91.51\n",
            "[TextRNN] Epoch 1 (1521.33s)\tAverage loss=0.418340\tDev F1=90.84\n",
            "[TextRNN] Epoch 2 (2303.49s)\tAverage loss=0.414675\tDev F1=91.47\n",
            "[TextRNN] Epoch 3 (3088.63s)\tAverage loss=0.414036\tDev F1=90.84\n",
            "[TextRNN] Epoch 4 (3877.68s)\tAverage loss=0.412990\tDev F1=90.55\n",
            "[TextRNN] Epoch 5 (4669.39s)\tAverage loss=0.412118\tDev F1=90.63\n",
            "[TextRNN] Epoch 6 (5463.23s)\tAverage loss=0.412559\tDev F1=90.07\n",
            "[TextRNN] Epoch 7 (6256.32s)\tAverage loss=0.412446\tDev F1=90.43\n",
            "[TextRNN] Epoch 8 (7048.42s)\tAverage loss=0.411614\tDev F1=90.70\n",
            "[TextRNN] Model saved as <TextRNN>\n",
            "[TextRNN] Epoch 9 (7842.36s)\tAverage loss=0.412075\tDev F1=90.89\n",
            "[TextRNN] Model saved as <TextRNN>\n",
            "[TextRNN] Training done (7888.30s)\n",
            "currrent vocab size is:  170119\n",
            "but capped to:  5000\n",
            "[TextRNN] Loaded model <TextRNN>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-wA6gEfWhl1",
        "colab_type": "text"
      },
      "source": [
        "### Accuracies on dev and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZBYLyyW-LdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c27252a6-44f9-4a19-d6d1-d29a01b3b53d"
      },
      "source": [
        "accuracy_dev = lstm.score(dev_cands, dev_cand_labels, batch_size=200)\n",
        "print(\"precision: {:.5f}\".format(accuracy_dev[0]), \n",
        "      \"recall: {:.5f}\".format(accuracy_dev[1]), \n",
        "      \"F-beta: {:.5f}\".format(accuracy_dev[2]))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision: 0.85984 recall: 0.96396 F-beta: 0.90892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlC3vfgA-Nse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08abea8c-687a-4094-98b9-2a2ab944cc18"
      },
      "source": [
        "accuracy_test = lstm.score(test_cands, test_cand_labels, batch_size=200)\n",
        "print(\"precision: {:.5f}\".format(accuracy_test[0]), \n",
        "      \"recall: {:.5f}\".format(accuracy_test[1]), \n",
        "      \"F-beta: {:.5f}\".format(accuracy_test[2]))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision: 0.85925 recall: 0.96318 F-beta: 0.90825\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}